{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks for Sequence Labeling\n",
        "\n",
        "\n",
        "You are a developer at a FinTech company that needs to automatically extract key pieces of information (like names, organizations, and dates) from financial news articles. This task, known as Named Entity Recognition (NER), requires the model to process a sequence of words and assign a specific label to each word.\n",
        "Since sentences have varying lengths and meaning depends on context (the sequence), a standard Feed-Forward Network is insufficient. Your task is to implement and compare different types of Recurrent Neural Networks (RNNs, GRUs, LSTMs) to solve this sequence labeling problem."
      ],
      "metadata": {
        "id": "iKtQe7f_RxzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasks:"
      ],
      "metadata": {
        "id": "g-_7sbN6UWL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim nltk scikit-learn matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F96KUxmuVF95",
        "outputId": "9124ba3f-a6af-46bd-9be7-837ff706c967"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word2Vec Model\n",
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "nltk.download('brown')  # Brown corpus for demo\n",
        "nltk.download('punkt')  # Tokenizer\n",
        "\n",
        "# Load and preprocess data\n",
        "sentences = brown.sents()  # Get sentences from the Brown corpus\n",
        "processed_sentences = [simple_preprocess(\" \".join(sent)) for sent in sentences]\n",
        "\n",
        "# printing\n",
        "print(f\"processed_sentences = {processed_sentences[:10]}, length = {len(processed_sentences)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(\n",
        "    sentences=processed_sentences,\n",
        "    vector_size=100,  # Dimensionality of word vectors\n",
        "    window=5,         # Context window size\n",
        "    min_count=2,      # Minimum word frequency\n",
        "    workers=4,        # Number of threads\n",
        "    sg=0              # CBOW (0) or Skip-gram (1)\n",
        ")\n",
        "\n",
        "# Save and load the model if needed\n",
        "model.save(\"word2vec.model\")\n",
        "model = Word2Vec.load(\"word2vec.model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jKcM5SLUl3r",
        "outputId": "62fa58a2-95db-4e4a-dab5-9704c29c52f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed_sentences = [['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlanta', 'recent', 'primary', 'election', 'produced', 'no', 'evidence', 'that', 'any', 'irregularities', 'took', 'place'], ['the', 'jury', 'further', 'said', 'in', 'term', 'end', 'presentments', 'that', 'the', 'city', 'executive', 'committee', 'which', 'had', 'over', 'all', 'charge', 'of', 'the', 'election', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted'], ['the', 'september', 'october', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', 'irregularities', 'in', 'the', 'hard', 'fought', 'primary', 'which', 'was', 'won', 'by', 'mayor', 'nominate', 'ivan', 'allen', 'jr'], ['only', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', 'the', 'jury', 'said', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city'], ['the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', 'georgia', 'registration', 'and', 'election', 'laws', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous'], ['it', 'recommended', 'that', 'fulton', 'legislators', 'act', 'to', 'have', 'these', 'laws', 'studied', 'and', 'revised', 'to', 'the', 'end', 'of', 'modernizing', 'and', 'improving', 'them'], ['the', 'grand', 'jury', 'commented', 'on', 'number', 'of', 'other', 'topics', 'among', 'them', 'the', 'atlanta', 'and', 'fulton', 'county', 'purchasing', 'departments', 'which', 'it', 'said', 'are', 'well', 'operated', 'and', 'follow', 'generally', 'accepted', 'practices', 'which', 'inure', 'to', 'the', 'best', 'interest', 'of', 'both', 'governments'], ['merger', 'proposed'], ['however', 'the', 'jury', 'said', 'it', 'believes', 'these', 'two', 'offices', 'should', 'be', 'combined', 'to', 'achieve', 'greater', 'efficiency', 'and', 'reduce', 'the', 'cost', 'of', 'administration'], ['the', 'city', 'purchasing', 'department', 'the', 'jury', 'said', 'is', 'lacking', 'in', 'experienced', 'clerical', 'personnel', 'as', 'result', 'of', 'city', 'personnel', 'policies']], length = 57340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding Similar words\n",
        "similar_words = model.wv.most_similar(\"learning\", topn=5)\n",
        "print(\"Words similar to 'learning':\", similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pseHHyvgVAec",
        "outputId": "fc92e8ce-4117-4fad-bd13-3f9f76987d95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'learning': [('wisdom', 0.9754779934883118), ('conduct', 0.9709805846214294), ('enjoyment', 0.9703553318977356), ('principles', 0.9697201251983643), ('roles', 0.9685952663421631)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "model.wv.save_word2vec_format(\"word2vec_vectors.txt\", binary=False)"
      ],
      "metadata": {
        "id": "XNl9_9vlVUmQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the library\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"Libraries imported. PyTorch Version:\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERwr-H32UVUD",
        "outputId": "2c87270a-2071-40c7-edc9-9168f5b44d94"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported. PyTorch Version: 2.9.0+cu128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Data Preparation and Embedding Layer\n",
        "\n",
        "1. **Tokenization and Mapping:** Load the NER dataset and create two dictionaries: a `word-to-index` map for the tokens, and a `tag-to-index` map for the labels (B-PER, I-PER, O, etc.).\n",
        "2. **Padding:** Since sentences have different lengths, implement a padding mechanism to ensure all input sequences have the same length .\n",
        "3. **Embedding:** Create a torch.nn.Embedding layer that will map the integer indices (from Task 1) to dense, continuous word vectors (e.g., dimension 100)."
      ],
      "metadata": {
        "id": "-NoO_p5zR7Sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task-1\n",
        "# Synthetic Data:\n",
        "# Data Format: (Sentence, Tags)\n",
        "# Tags: B- (Beginning), I- (Inside), O (Outside)\n",
        "training_data = [\n",
        "    (\"Elon Musk is the CEO of Tesla\".split(), [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\"]),\n",
        "    (\"Apple released a new iPhone on Monday\".split(), [\"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-DATE\"]),\n",
        "    (\"JP Morgan Chase reported strong profits\".split(), [\"B-ORG\", \"I-ORG\", \"I-ORG\", \"O\", \"O\", \"O\"]),\n",
        "    (\"Stocks fell on Tuesday after the announcement\".split(), [\"O\", \"O\", \"O\", \"B-DATE\", \"O\", \"O\", \"O\"]),\n",
        "    (\"Amazon plans to hire more engineers in 2024\".split(), [\"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-DATE\"]),\n",
        "    (\"Satya Nadella spoke about AI at Microsoft\".split(), [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\"]),\n",
        "]\n",
        "\n",
        "# Print a sample to check structure\n",
        "print(f\"Sample Text: {training_data[0][0]}\")\n",
        "print(f\"Sample Tags: {training_data[0][1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyvXHeiJWbe3",
        "outputId": "747912bc-c8fe-4702-9c9f-eba6b04fc056"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Text: ['Elon', 'Musk', 'is', 'the', 'CEO', 'of', 'Tesla']\n",
            "Sample Tags: ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-ORG']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Mapping\n",
        "word_to_index = {\"<PAD>\": 0}\n",
        "tags = {\"<PAD>\": 0}\n",
        "\n",
        "for sentence, tag_sequence in training_data:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_index:\n",
        "            word_to_index[word] = len(word_to_index)\n",
        "    for tag in tag_sequence:\n",
        "        if tag not in tags:\n",
        "            tags[tag] = len(tags)\n",
        "\n",
        "tag_to_index = tags\n",
        "index_to_tag = {idx: tag for tag, idx in tag_to_index.items()}\n",
        "\n",
        "print(f\"Vocabulary Size: {len(word_to_index)}\")\n",
        "print(f\"Tags: {tag_to_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZa1wDMhWad6",
        "outputId": "d47f8d2c-d81b-4dcf-cc12-d89451e7e5c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 41\n",
            "Tags: {'<PAD>': 0, 'B-PER': 1, 'I-PER': 2, 'O': 3, 'B-ORG': 4, 'B-DATE': 5, 'I-ORG': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD4zA-ySRt8C",
        "outputId": "3acf767c-a6c0-4e38-dad1-01ee62465362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Input Tensor: torch.Size([6, 8])\n",
            "Shape of Target Tensor: torch.Size([6, 8])\n"
          ]
        }
      ],
      "source": [
        "# Padding:\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "# Convert all data to tensors\n",
        "X = [prepare_sequence(s[0], word_to_index) for s in training_data]\n",
        "y = [prepare_sequence(s[1], tag_to_index) for s in training_data]\n",
        "\n",
        "# Pad sequences to the max length in the batch\n",
        "# batch_first=True makes the output shape (Batch_Size, Seq_Len)\n",
        "X_padded = pad_sequence(X, batch_first=True, padding_value=word_to_index[\"<PAD>\"])\n",
        "y_padded = pad_sequence(y, batch_first=True, padding_value=tag_to_index[\"<PAD>\"])\n",
        "\n",
        "print(\"Shape of Input Tensor:\", X_padded.shape)\n",
        "print(\"Shape of Target Tensor:\", y_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "# Hyperparameters\n",
        "VOCAB_SIZE = len(word_to_index)\n",
        "EMBEDDING_DIM = 100  # As requested\n",
        "\n",
        "# 1. Define the Embedding Layer\n",
        "embedding_layer = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM, padding_idx=word_to_index[\"<PAD>\"])\n",
        "\n",
        "# Forward pass (Lookup)\n",
        "input_indices = X_padded # Use the padded input from the previous step\n",
        "dense_vectors = embedding_layer(input_indices)\n",
        "\n",
        "print(f\"\\nInput Indices Shape: {input_indices.shape}\")\n",
        "print(f\"Dense Vectors Shape: {dense_vectors.shape}\")\n",
        "\n",
        "# 3. Verification\n",
        "pad_vector = dense_vectors[0][-1]\n",
        "print(f\"\\nVector for PAD token (Sum of values): {pad_vector.sum().item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgQkYXIeYe0L",
        "outputId": "22f22297-45a7-4145-a18e-e641c0e5f618"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input Indices Shape: torch.Size([6, 8])\n",
            "Dense Vectors Shape: torch.Size([6, 8, 100])\n",
            "\n",
            "Vector for PAD token (Sum of values): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Building the LSTM Sequence Labeler\n",
        "Implement a PyTorch class LSTMNERSegmenter that utilizes an LSTM for the sequence labeling task.\n",
        "\n",
        "1. `Initialization (__init__)`:\n",
        "  * Define the nn.Embedding layer (from Task 1).\n",
        "  *  Define a Bidirectional LSTM layer (nn.LSTM).\n",
        "\n",
        "    Input Size: Embedding dimension.\n",
        "    Hidden Size: Choose a reasonable hidden dimension (e.g., 256).\n",
        "    bidirectional=True: Essential for sequence labeling.\n",
        "  \n",
        "  * Define a final Linear Layer (nn.Linear) that maps the output of the Bi-LSTM (which is ) to the number of unique tags/labels.\n",
        "\n",
        "2. `Forward Pass (forward)`:\n",
        "* Pass the input indices through the embedding layer.\n",
        "* Pass the embeddings into the Bi-LSTM.\n",
        "* Pass the LSTM output through the final linear layer."
      ],
      "metadata": {
        "id": "k0-7AB1uSi5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task-2\n",
        "class LSTMNERSegmenter(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim=256):\n",
        "        super(LSTMNERSegmenter, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.hidden2tag = nn.Linear(hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.embedding(x)\n",
        "\n",
        "        lstm_out, _ = self.lstm(embeddings)\n",
        "\n",
        "        tag_space = self.hidden2tag(lstm_out)\n",
        "\n",
        "        return tag_space"
      ],
      "metadata": {
        "id": "YqxtTLNNTiZI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiation\n",
        "\n",
        "# Hyperparameters\n",
        "VOCAB_SIZE = len(word_to_index)\n",
        "TAGSET_SIZE = len(tag_to_index)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTMNERSegmenter(VOCAB_SIZE, TAGSET_SIZE, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "\n",
        "# Check architecture\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_4CliJiVzhP",
        "outputId": "b6db5c50-96aa-456e-e36e-9ca99c9efb05"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMNERSegmenter(\n",
            "  (embedding): Embedding(41, 100, padding_idx=0)\n",
            "  (lstm): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=512, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Training and Evaluation\n",
        "\n",
        "1. Define the `Loss Function` (e.g., nn.CrossEntropyLoss) and the Optimizer (e.g., optim.Adam).\n",
        "2. **Implement the training loop:** iterate through batches of the dataset, perform the forward pass, calculate the loss, perform backpropagation (loss.backward()), and update the weights (optimizer.step()).\n",
        "3. **Evaluation:** Calculate the `token-level` accuracy (the percentage of words correctly tagged). Briefly discuss why the more robust `F1-Score` is preferred over simple accuracy for the NER task, which involves class imbalance (many 'O' tags).\n"
      ],
      "metadata": {
        "id": "VbukbsVVTj26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task-3\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Hyperparameters\n",
        "LEARNING_RATE = 0.01\n",
        "EPOCHS = 10\n",
        "\n",
        "# 2. Initialize Model, Loss, and Optimizer\n",
        "model = LSTMNERSegmenter(VOCAB_SIZE, TAGSET_SIZE, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "PAD_IDX = tag_to_index[\"<PAD>\"] # Get the index for the padding token\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX) # Ignore padding in loss calculation\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 3. Helper Function for Accuracy\n",
        "def categorical_accuracy(preds, y, tag_pad_idx=0):\n",
        "    max_preds = preds.argmax(dim=2, keepdim=True).squeeze(2)\n",
        "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements[:, 0], non_pad_elements[:, 1]].eq(\n",
        "              y[non_pad_elements[:, 0], non_pad_elements[:, 1]])\n",
        "\n",
        "    # Ensure the divisor is on the same device as other tensors\n",
        "    return correct.sum() / torch.tensor([y[non_pad_elements[:, 0], non_pad_elements[:, 1]].shape[0]], dtype=torch.float32).to(y.device)"
      ],
      "metadata": {
        "id": "r4V-9Cx0TtUg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "X_padded = X_padded.to(device)\n",
        "y_padded = y_padded.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "print(f\"Training on {device}...\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train() # Set model to training mode\n",
        "    optimizer.zero_grad() # Zero the gradients before running the backward pass\n",
        "\n",
        "    # Forward pass\n",
        "    predictions = model(X_padded)\n",
        "\n",
        "    # Reshape for loss calculation: (N * L, C) where N=batch, L=seq_len, C=num_classes\n",
        "    predictions = predictions.view(-1, predictions.shape[-1])\n",
        "    # Reshape target for loss calculation: (N * L)\n",
        "    target = y_padded.view(-1)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(predictions, target)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    acc = categorical_accuracy(model(X_padded), y_padded, PAD_IDX)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        print(f\"Epoch: {epoch+1:02} | Loss: {loss.item():.4f} | Accuracy: {acc.item()*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxkG8hB-afD7",
        "outputId": "6788ea72-49ad-4753-df5e-140e013e51cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda...\n",
            "Epoch: 02 | Loss: 1.0412 | Accuracy: 85.71%\n",
            "Epoch: 04 | Loss: 0.2295 | Accuracy: 100.00%\n",
            "Epoch: 06 | Loss: 0.1726 | Accuracy: 100.00%\n",
            "Epoch: 08 | Loss: 0.0312 | Accuracy: 100.00%\n",
            "Epoch: 10 | Loss: 0.0085 | Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4: Architecture Comparison (Theoretical)\n",
        "\n",
        "Briefly modify your code (or simply discuss the required modifications) to compare:\n",
        "\n",
        "* `Simple RNN vs. LSTM vs. GRU.` Explain the conceptual difference between the Cell State (in LSTM) and the simple Hidden State (in RNN/GRU)."
      ],
      "metadata": {
        "id": "XOZ-DSbTT1l5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e82419c"
      },
      "source": [
        "### Task 4\n",
        "\n",
        "#### Simple RNN vs. LSTM vs. GRU\n",
        "\n",
        "*   **Simple RNN (Recurrent Neural Network):** These are the most basic form of RNNs. They process sequences by passing information from one step to the next in a hidden state. However, they suffer from the vanishing/exploding gradient problem, making them ineffective at capturing long-term dependencies in sequences.\n",
        "\n",
        "*   **LSTM (Long Short-Term Memory):** LSTMs address the vanishing gradient problem through a more complex architecture that includes three 'gates' (input, forget, and output) and a 'cell state'. These gates regulate the flow of information into and out of the cell state, allowing the network to selectively remember or forget information over long sequences. This makes LSTMs very effective at learning long-term dependencies.\n",
        "\n",
        "*   **GRU (Gated Recurrent Unit):** GRUs are a simpler variant of LSTMs, combining the forget and input gates into a single 'update gate' and merging the cell state and hidden state. They also have a 'reset gate'. GRUs are computationally less expensive than LSTMs and often perform similarly, especially on smaller datasets.\n",
        "\n",
        "#### Cell State (LSTM) vs. Hidden State (RNN/GRU)\n",
        "\n",
        "*   **Cell State (LSTM):** The cell state in an LSTM acts as a 'memory highway' that runs straight through the entire chain of the LSTM. It is largely unaffected by the operations of the gates unless they explicitly act on it. This allows information to flow through many time steps without being significantly altered or vanishing, making it ideal for retaining long-term dependencies. The cell state is explicitly controlled by the forget and input gates.\n",
        "\n",
        "*   **Hidden State (RNN/GRU):** In Simple RNNs and GRUs, there is only a hidden state (in GRUs, it combines the functions of LSTM's hidden state and cell state). The hidden state is constantly updated at each time step based on the current input and the previous hidden state. While it carries information forward, in Simple RNNs, it is much more susceptible to vanishing gradients, leading to a loss of information about distant past inputs. GRUs mitigate this to a large extent with their gating mechanisms, making their hidden state more robust than a Simple RNN's, but it lacks the separate, less-interrupted memory pathway of LSTM's cell state.\n",
        "\n",
        "#### Bidirectional LSTM (Bi-LSTM) vs. Unidirectional LSTM for NER\n",
        "\n",
        "A Bi-LSTM is inherently better suited than a unidirectional LSTM for sequence labeling tasks like Named Entity Recognition because NER often requires understanding context from *both* the past and the future words in a sentence to correctly classify a given word. A unidirectional LSTM processes a sequence only from left-to-right (or right-to-left), meaning its prediction for a word 'X' can only consider words that came before 'X' (or after, if processing reversed). In contrast, a Bi-LSTM consists of two LSTMs: one processing the sequence forward and another processing it backward. Their outputs are then concatenated. This allows the model to capture rich contextual information from both preceding and succeeding words, which is crucial for accurately identifying entities. For example, to classify 'Morgan' in 'JP Morgan Chase', knowing 'Chase' follows is as important as knowing 'JP' precedes it.\n",
        "\n",
        "#### Code Modifications for Comparison:\n",
        "\n",
        "To compare these architectures, you would modify the `LSTMNERSegmenter` class. The primary change would be replacing `nn.LSTM` with `nn.RNN` for a Simple RNN or `nn.GRU` for a Gated Recurrent Unit. The input and output dimensions of these layers would remain similar, but you would need to adjust for the specific return values (e.g., `nn.RNN` and `nn.GRU` typically return only the output and the final hidden state, without a separate cell state).\n",
        "\n",
        "For example, to use a GRU:\n",
        "```python\n",
        "class GRUNERSegmenter(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim=256):\n",
        "        super(GRUNERSegmenter, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        # Replace LSTM with GRU\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.embedding(x)\n",
        "        # GRU returns output, h_n (no cell state)\n",
        "        gru_out, _ = self.gru(embeddings)\n",
        "        tag_space = self.hidden2tag(gru_out)\n",
        "        return tag_space\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c54ed51",
        "outputId": "5ab9675b-af35-4f80-f61d-a6130ff0194f"
      },
      "source": [
        "# Output Snapshot: Displaying True vs. Predicted Labels\n",
        "\n",
        "# Select a sample from the training data\n",
        "sample_index = 0 # You can change this to see other samples\n",
        "sample_sentence_words = training_data[sample_index][0]\n",
        "sample_true_tags_str = training_data[sample_index][1]\n",
        "\n",
        "print(f\"Sample Sentence: {' '.join(sample_sentence_words)}\")\n",
        "print(f\"True Tags: {sample_true_tags_str}\")\n",
        "\n",
        "# Prepare the sample sentence for the model\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad(): # Disable gradient calculations\n",
        "    input_indices = prepare_sequence(sample_sentence_words, word_to_index).unsqueeze(0).to(device) # Add batch dimension and move to device\n",
        "\n",
        "    # Get predictions\n",
        "    raw_predictions = model(input_indices)\n",
        "\n",
        "    # Get the predicted tag index for each word\n",
        "    # raw_predictions is (batch_size, seq_len, tagset_size)\n",
        "    # We need to take argmax along the last dimension\n",
        "    predicted_tag_indices = raw_predictions.argmax(dim=2).squeeze(0) # Remove batch dimension\n",
        "\n",
        "    # Convert predicted indices back to tag strings\n",
        "    predicted_tags_str = [index_to_tag[idx.item()] for idx in predicted_tag_indices]\n",
        "\n",
        "# Trim padding tags if necessary (though our example padding is simple)\n",
        "# Find the actual length of the original sentence, excluding padding words\n",
        "original_sentence_length = len(sample_sentence_words)\n",
        "predicted_tags_trimmed = predicted_tags_str[:original_sentence_length]\n",
        "\n",
        "print(f\"Predicted Tags: {predicted_tags_trimmed}\")\n",
        "\n",
        "# Visual comparison\n",
        "print(\"\\n--- Visual Comparison ---\")\n",
        "for i, (word, true_tag, pred_tag) in enumerate(zip(sample_sentence_words, sample_true_tags_str, predicted_tags_trimmed)):\n",
        "    print(f\"Word: {word:<10} | True: {true_tag:<8} | Pred: {pred_tag:<8}\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Sentence: Elon Musk is the CEO of Tesla\n",
            "True Tags: ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-ORG']\n",
            "Predicted Tags: ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-ORG']\n",
            "\n",
            "--- Visual Comparison ---\n",
            "Word: Elon       | True: B-PER    | Pred: B-PER   \n",
            "Word: Musk       | True: I-PER    | Pred: I-PER   \n",
            "Word: is         | True: O        | Pred: O       \n",
            "Word: the        | True: O        | Pred: O       \n",
            "Word: CEO        | True: O        | Pred: O       \n",
            "Word: of         | True: O        | Pred: O       \n",
            "Word: Tesla      | True: B-ORG    | Pred: B-ORG   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deliverables\n",
        "\n",
        "* A fully commented Python Notebook (.ipynb) implementing the Bi-LSTM NER model (Tasks 1-3).\n",
        "* Analysis: A short theoretical comparison (100 words) explaining why a Bi-LSTM is inherently better suited than a unidirectional LSTM for Sequence Labeling tasks like NER.\n",
        "* Output Snapshot: Show a sample sentence from the test set, displaying the true labels and the model's predicted labels."
      ],
      "metadata": {
        "id": "FZGz3tszTuiS"
      }
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Statistical Language Modeling: The \"Lightweight\" Autocomplete Engine**\n",
        "\n",
        "You have been hired as a Junior NLP Engineer by a mobile software startup. The company is developing a keyboard application for low-resource feature phones that cannot run heavy Deep Learning models (like Transformers).\n",
        "\n",
        "\n",
        "Your task is to build a lightweight Predictive Text Engine using statistical N-Grams. The system must learn from a corpus of text, handle words it hasn't seen frequently (Smoothing), generate coherent sentence completions, and mathematically prove its accuracy (Perplexity).\n"
      ],
      "metadata": {
        "id": "G7x8oaeqvngb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "20xATuL3V_Qq"
      },
      "outputs": [],
      "source": [
        "# Importing Required Libraries\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "import math\n",
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6ykvDQNV-Nw"
      },
      "source": [
        "#### **Task-1: N-Gram Extraction**\n",
        "\n",
        "#### What is an N-Gram?\n",
        "\n",
        "An N-Gram is a contiguous sequence of N items (words, characters, etc.) from a given text.\n",
        "\n",
        "For example, in the sentence \"I love machine learning\", the 2-grams (bigrams) are:\n",
        "\n",
        "[\"I love\", \"love machine\", \"machine learning\"]\n",
        "\n",
        "#### N-Gram Probability Equation\n",
        "The probability of a word \\( w_n \\) given its history \\( h \\) in an n-gram model is:\n",
        "$$\n",
        "P(w_n \\mid h) = \\frac{C(h, w_n)}{\\sum_{w'} C(h, w')}\n",
        "$$\n",
        "Where:\n",
        "- \\( C(h, w_n) \\): Count of occurrences of \\( h \\) followed by \\( w_n \\)\n",
        "- \\( h \\): Context (history of n-1 words)\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "##### **Task:**\n",
        "1. Write a function `generate_ngrams(text, n)` that takes a corpus of text and breaks it down into contiguous sequences of `N` items.\n",
        "```\n",
        "Input: \"I love machine learning\"\n",
        "Character-Level Bigrams: [('#', 'I'), ('I', ' '), (' ', 'l'), ('l', 'o'), ('o', 'v'), ('v', 'e'), ('e', ' '), (' ', 'm'), ('m', 'a'), ('a', 'c'), ('c', 'h'), ('h', 'i'), ('i', 'n'), ('n', 'e'), ('e', ' '), (' ', 'l'), ('l', 'e'), ('e', 'a'), ('a', 'r'), ('r', 'n'), ('n', 'i'), ('i', 'n'), ('n', 'g')]\n",
        "\n",
        "```\n",
        "\n",
        "2. Build an n-gram language model from the corpus. Write a function `build_ngram_model(corpus, n)` that takes the corpus of text and breaks it down into contiguous `N` items, and return a probability distribution for each context.\n",
        "\n",
        "```\n",
        "Input: \"I love machine learning\"\n",
        "output: {('#',): Counter({'I': 1.0}),\n",
        "             ('I',): Counter({' ': 1.0}),\n",
        "             (' ',): Counter({'l': 0.6666666666666666,\n",
        "                      'm': 0.3333333333333333}),\n",
        "             ('l',): Counter({'o': 0.5, 'e': 0.5}),\n",
        "             ('o',): Counter({'v': 1.0}),\n",
        "             ('v',): Counter({'e': 1.0}),\n",
        "             ('e',): Counter({' ': 0.6666666666666666,\n",
        "                      'a': 0.3333333333333333}),\n",
        "             ('m',): Counter({'a': 1.0}),\n",
        "             ('a',): Counter({'c': 0.5, 'r': 0.5}),\n",
        "             ('c',): Counter({'h': 1.0}),\n",
        "             ('h',): Counter({'i': 1.0}),\n",
        "             ('i',): Counter({'n': 1.0}),\n",
        "             ('n',): Counter({'e': 0.3333333333333333,\n",
        "                      'i': 0.3333333333333333,\n",
        "                      'g': 0.3333333333333333}),\n",
        "             ('r',): Counter({'n': 1.0})}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ONUihztsV6Qk"
      },
      "outputs": [],
      "source": [
        "def generate_ngrams(text, n):\n",
        "    p = ['#'] * (n - 1)\n",
        "    ptext = p + list(text) + p\n",
        "    ngrams = []\n",
        "    for i in range(len(ptext) - n):\n",
        "        ngrams.append(tuple(ptext[i:i+n]))\n",
        "    return ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zvT0qMoWawC",
        "outputId": "a7810a5d-5034-4c5a-83a7-c79b24bb7786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character-Level Bigrams: [('#', 'I'), ('I', ' '), (' ', 'l'), ('l', 'o'), ('o', 'v'), ('v', 'e'), ('e', ' '), (' ', 'm'), ('m', 'a'), ('a', 'c'), ('c', 'h'), ('h', 'i'), ('i', 'n'), ('n', 'e'), ('e', ' '), (' ', 'l'), ('l', 'e'), ('e', 'a'), ('a', 'r'), ('r', 'n'), ('n', 'i'), ('i', 'n'), ('n', 'g')]\n"
          ]
        }
      ],
      "source": [
        "# Example Text\n",
        "text = \"I love machine learning\"\n",
        "\n",
        "# Generate and display bigrams (2-grams)\n",
        "bigrams = generate_ngrams(text, 2)\n",
        "print(\"Character-Level Bigrams:\", bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OMWOU8D9bj-b"
      },
      "outputs": [],
      "source": [
        "def build_ngram_model(corpus, n):\n",
        "    model = defaultdict(Counter)\n",
        "    ngrams = generate_ngrams(corpus, n)\n",
        "\n",
        "    for ngram in ngrams:\n",
        "        context = ngram[:-1]\n",
        "        word = ngram[-1]\n",
        "        model[context][word]\n",
        "        model[context][word] += 1\n",
        "\n",
        "    for context in model:\n",
        "        total_count = sum(model[context].values())\n",
        "        for word in model[context]:\n",
        "            model[context][word] /= total_count\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test\n",
        "corpus = \"I love machine learning\"\n",
        "model = build_ngram_model(corpus, 2)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy5HZlTpyMgF",
        "outputId": "1a6952b3-83fd-480a-9101-f92faec46bf6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(collections.Counter,\n",
              "            {('#',): Counter({'I': 1.0}),\n",
              "             ('I',): Counter({' ': 1.0}),\n",
              "             (' ',): Counter({'l': 0.6666666666666666,\n",
              "                      'm': 0.3333333333333333}),\n",
              "             ('l',): Counter({'o': 0.5, 'e': 0.5}),\n",
              "             ('o',): Counter({'v': 1.0}),\n",
              "             ('v',): Counter({'e': 1.0}),\n",
              "             ('e',): Counter({' ': 0.6666666666666666,\n",
              "                      'a': 0.3333333333333333}),\n",
              "             ('m',): Counter({'a': 1.0}),\n",
              "             ('a',): Counter({'c': 0.5, 'r': 0.5}),\n",
              "             ('c',): Counter({'h': 1.0}),\n",
              "             ('h',): Counter({'i': 1.0}),\n",
              "             ('i',): Counter({'n': 1.0}),\n",
              "             ('n',): Counter({'e': 0.3333333333333333,\n",
              "                      'i': 0.3333333333333333,\n",
              "                      'g': 0.3333333333333333}),\n",
              "             ('r',): Counter({'n': 1.0})})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK7mI5iyWipq"
      },
      "source": [
        "#### **Task 2: Handling Sparsity (Smoothing)**\n",
        "Real-world data is sparse. If a user types a word combination not found in your training data, your model returns a probability of 0, crashing the system. Implement Add-$\\alpha $ (Laplace) Smoothing.\n",
        "\n",
        "Smoothing assigns a small non-zero probability to unseen n-grams.\n",
        "\n",
        "#### Smoothing Equation\n",
        "With smoothing, the probability becomes:\n",
        "$$\n",
        "P(w_n \\mid h) = \\frac{C(h, w_n) + \\alpha}{\\sum_{w'} C(h, w') + \\alpha \\times |V|}\n",
        "$$\n",
        "Where:\n",
        "- $\\alpha $: Smoothing parameter (default is 1)\n",
        "- \\( |V| \\): Vocabulary size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rak99gJ7WasJ"
      },
      "outputs": [],
      "source": [
        "def add_smoothing(model, vocabulary, alpha=1.0):\n",
        "    model_smoothed = defaultdict(dict)\n",
        "    V = len(vocabulary)\n",
        "\n",
        "    for context, counter in model.items():\n",
        "        total_count = sum(counter.values())\n",
        "        denom = total_count + alpha * V\n",
        "\n",
        "        for word in vocabulary:\n",
        "            count = counter.get(word, 0)\n",
        "            model_smoothed[context][word] = (count + alpha) / denom\n",
        "\n",
        "    return model_smoothed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set()\n",
        "for counter in model.values():\n",
        "    vocabulary.update(counter.keys())\n",
        "\n",
        "model = add_smoothing(model, vocabulary, alpha=1.0)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9BJ3Jf5N4Zt",
        "outputId": "5631a206-9015-40b5-a8c2-6d2b2218a96e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(dict,\n",
              "            {('#',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.13333333333333333,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('I',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.13333333333333333,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667},\n",
              "             (' ',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.1111111111111111,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.08888888888888888,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('l',): {'e': 0.1,\n",
              "              'o': 0.1,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('o',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.13333333333333333,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('v',): {'e': 0.13333333333333333,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('e',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.1111111111111111,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.08888888888888888,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('m',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.13333333333333333,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('a',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.1,\n",
              "              'c': 0.1,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('c',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.13333333333333333,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('h',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.13333333333333333},\n",
              "             ('i',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.13333333333333333,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667},\n",
              "             ('n',): {'e': 0.08888888888888888,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.08888888888888888,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.06666666666666667,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.08888888888888888},\n",
              "             ('r',): {'e': 0.06666666666666667,\n",
              "              'o': 0.06666666666666667,\n",
              "              'v': 0.06666666666666667,\n",
              "              'r': 0.06666666666666667,\n",
              "              'c': 0.06666666666666667,\n",
              "              'g': 0.06666666666666667,\n",
              "              'l': 0.06666666666666667,\n",
              "              'h': 0.06666666666666667,\n",
              "              'I': 0.06666666666666667,\n",
              "              ' ': 0.06666666666666667,\n",
              "              'n': 0.13333333333333333,\n",
              "              'm': 0.06666666666666667,\n",
              "              'a': 0.06666666666666667,\n",
              "              'i': 0.06666666666666667}})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUUvZwVYW1-F"
      },
      "source": [
        "#### **Task 3: Text Generation**\n",
        "Create a function `generate_text(context, length)`:\n",
        "1. Take a starting word/phrase (context).\n",
        "2. Look up the probabilities of all possible next words.\n",
        "3. Sample the next word based on these probabilities.\n",
        "4. Update the context and repeat until the desired length is reached.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_G12hnRLWapc"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, n, start_text, length=100):\n",
        "    generated_chars = list(start_text)\n",
        "    current_sequence_for_context = list(start_text)\n",
        "    if len(start_text) < (n - 1):\n",
        "        current_sequence_for_context = ['#'] * (n - 1 - len(start_text)) + current_sequence_for_context\n",
        "\n",
        "    for _ in range(length - len(start_text)):\n",
        "        context = tuple(current_sequence_for_context[-(n - 1):])\n",
        "\n",
        "        next_char_probabilities = model.get(context, {})\n",
        "\n",
        "        if not next_char_probabilities:\n",
        "            all_known_chars = set()\n",
        "            for k in model.keys():\n",
        "                all_known_chars.update(model[k].keys())\n",
        "\n",
        "            if all_known_chars:\n",
        "                next_char = random.choice(list(all_known_chars))\n",
        "            else:\n",
        "                print(f\"Warning: Context '{context}' not found and no known characters in model. Stopping generation.\")\n",
        "                break\n",
        "        else:\n",
        "            next_char = random.choices(list(next_char_probabilities.keys()),\n",
        "                                       weights=list(next_char_probabilities.values()))[0]\n",
        "\n",
        "        generated_chars.append(next_char)\n",
        "        current_sequence_for_context.append(next_char)\n",
        "\n",
        "    return \"\".join(generated_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLoX7FkBWag1",
        "outputId": "453e7887-72f0-4207-d043-b2b56bffd9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: he n-gram model\n"
          ]
        }
      ],
      "source": [
        "# Sample text\n",
        "text = \"hello world this is a sample text for testing the n-gram model\"\n",
        "\n",
        "# Build a bigram model\n",
        "bigram_model = build_ngram_model(text, 3)\n",
        "\n",
        "# Generate text\n",
        "generated = generate_text(bigram_model, 3, \"he\", 15)\n",
        "print(f\"Generated text: {generated}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQNyoSdyXGSE"
      },
      "source": [
        "#### **Task 4: Model Evaluation (Perplexity)**\n",
        "You need to prove to your manager that your model is actually learning. Implement the Perplexity metric on a held-out test set. Lower perplexity indicates a better model.\n",
        "\n",
        "Action: Calculate the perplexity of your model on a short unseen test sentence (e.g., \"The machine learning algorithm\").\n",
        "\n",
        "#### **Perplexity**\n",
        "\n",
        "Perplexity is a common metric for evaluating language models. Lower perplexity indicates a better model.\n",
        "\n",
        "#### Perplexity Equation\n",
        "Perplexity measures how well a language model predicts a test dataset:\n",
        "$$\n",
        "PP(W) = 2^{-\\frac{1}{N} \\sum_{i=1}^{N} \\log_2 P(w_i \\mid h_i)}\n",
        "$$\n",
        "Where:\n",
        "- \\( W \\): Sequence of words\n",
        "- \\( N \\): Total number of words in the sequence\n",
        "- $ P(w_i \\mid h_i) $: Probability of word $w_i$ given its history $ h_i $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QUqppwpAXFuH"
      },
      "outputs": [],
      "source": [
        "def calculate_perplexity(model, n, test_text, vocabulary):\n",
        "    log_sum_prob = 0.0\n",
        "    N = 0\n",
        "    padded_text = ['#'] * (n - 1) + list(test_text)\n",
        "\n",
        "    for i in range(n - 1, len(padded_text)):\n",
        "        context = tuple(padded_text[i - (n - 1):i])\n",
        "        word = padded_text[i]\n",
        "        con_prob = model.get(context, {})\n",
        "        if context not in model:\n",
        "            V = len(vocabulary)\n",
        "            alpha = 1.0\n",
        "            prob = alpha / (alpha * V)\n",
        "        else:\n",
        "            prob = con_prob.get(word, 0.0)\n",
        "        if prob == 0:\n",
        "            return float('inf')\n",
        "\n",
        "        log_sum_prob += math.log2(prob)\n",
        "        N += 1\n",
        "\n",
        "    if N == 0:\n",
        "        return float('inf')\n",
        "\n",
        "    perplexity = 2 ** (-log_sum_prob / N)\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's create a more substantial training corpus\n",
        "training_corpus = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "She sells seashells by the seashore.\n",
        "How much wood would a woodchuck chuck if a woodchuck could chuck wood?\n",
        "To be or not to be, that is the question.\n",
        "All that glitters is not gold.\n",
        "A journey of a thousand miles begins with a single step.\n",
        "Actions speak louder than words.\n",
        "Beauty is in the eye of the beholder.\n",
        "Every cloud has a silver lining.\n",
        "Fortune favors the bold and brave.\n",
        "Life is like a box of chocolates.\n",
        "The early bird catches the worm.\n",
        "Where there's smoke, there's fire.\n",
        "Time heals all wounds and teaches all things.\n",
        "Knowledge is power, and power corrupts.\n",
        "Practice makes perfect, but nobody's perfect.\n",
        "The pen is mightier than the sword.\n",
        "When in Rome, do as the Romans do.\n",
        "A picture is worth a thousand words.\n",
        "Better late than never, but never late is better.\n",
        "Experience is the best teacher of all things.\n",
        "Laughter is the best medicine for the soul.\n",
        "Music soothes the savage beast within us.\n",
        "Nothing ventured, nothing gained in life.\n",
        "The grass is always greener on the other side.\n",
        "\"\"\"\n",
        "\n",
        "# Clean the corpus\n",
        "training_corpus = ''.join(c.lower() for c in training_corpus if c.isalnum() or c.isspace())"
      ],
      "metadata": {
        "id": "VH5m9Bkscnae"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "qZZ5c029iDEJ",
        "outputId": "4b128847-bea5-4ecb-a36b-0706fa041f07"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nthe quick brown fox jumps over the lazy dog\\nshe sells seashells by the seashore\\nhow much wood would a woodchuck chuck if a woodchuck could chuck wood\\nto be or not to be that is the question\\nall that glitters is not gold\\na journey of a thousand miles begins with a single step\\nactions speak louder than words\\nbeauty is in the eye of the beholder\\nevery cloud has a silver lining\\nfortune favors the bold and brave\\nlife is like a box of chocolates\\nthe early bird catches the worm\\nwhere theres smoke theres fire\\ntime heals all wounds and teaches all things\\nknowledge is power and power corrupts\\npractice makes perfect but nobodys perfect\\nthe pen is mightier than the sword\\nwhen in rome do as the romans do\\na picture is worth a thousand words\\nbetter late than never but never late is better\\nexperience is the best teacher of all things\\nlaughter is the best medicine for the soul\\nmusic soothes the savage beast within us\\nnothing ventured nothing gained in life\\nthe grass is always greener on the other side\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_models(corpus):\n",
        "    models = {}\n",
        "    for n in [2, 3, 4]:\n",
        "        raw_model = build_ngram_model(corpus, n)\n",
        "\n",
        "        vocabulary = set()\n",
        "        for context_counter in raw_model.values():\n",
        "            vocabulary.update(context_counter.keys())\n",
        "        vocabulary.update(list(corpus))\n",
        "\n",
        "        smoothed_model = add_smoothing(raw_model, vocabulary, alpha=1.0)\n",
        "\n",
        "        models[n] = {'model': smoothed_model, 'vocabulary': vocabulary}\n",
        "    return models\n",
        "\n",
        "models = build_models(training_corpus)"
      ],
      "metadata": {
        "id": "MF8RoYtDUVCj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_samples(models, num_samples=10, sample_length=40):\n",
        "    results = defaultdict(list)\n",
        "    for n, model_data in models.items():\n",
        "        current_model = model_data['model']\n",
        "        vocabulary = model_data['vocabulary']\n",
        "        print(f\"\\nEvaluating {n}-gram model...\")\n",
        "        for i in range(num_samples):\n",
        "            start_char = random.choice(list(vocabulary))\n",
        "            generated_text = generate_text(current_model, n, start_char, length=sample_length)\n",
        "            perplexity_score = calculate_perplexity(current_model, n, generated_text, vocabulary)\n",
        "\n",
        "            results[n].append({'text': generated_text, 'perplexity': perplexity_score})\n",
        "            print(f\"  Sample {i+1}: '{generated_text[:20]}...' Perplexity: {perplexity_score:.2f}\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "13kHhr1ccIQh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_samples(models)\n",
        "print(\"\\n=== Overall Statistics ===\")\n",
        "for n in models.keys():\n",
        "    perplexities = [sample['perplexity'] for sample in results[n]]\n",
        "    min_perp = min(perplexities)\n",
        "    max_perp = max(perplexities)\n",
        "    avg_perp = sum(perplexities) / len(perplexities)\n",
        "\n",
        "    print(f\"\\n{n}-gram Model Statistics:\")\n",
        "    print(f\"Minimum Perplexity: {min_perp:.2f}\")\n",
        "    print(f\"Maximum Perplexity: {max_perp:.2f}\")\n",
        "    print(f\"Average Perplexity: {avg_perp:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy_JvJ8scaAU",
        "outputId": "25904901-9caa-417b-96ea-ee1f206c94ae",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating 2-gram model...\n",
            "  Sample 1: 'vpmprxrbwsomtds \n",
            "mzs...' Perplexity: 27.96\n",
            "  Sample 2: 'hopgkemrcrx\n",
            "zvphxsag...' Perplexity: 28.33\n",
            "  Sample 3: 'v\n",
            "fkgipuzrbofvtoy\n",
            "kz...' Perplexity: 28.47\n",
            "  Sample 4: 'nfpdlcmjuzjm fqxapph...' Perplexity: 28.63\n",
            "  Sample 5: 'fgjdsxaxnwb hyz ovkw...' Perplexity: 28.16\n",
            "  Sample 6: 'zbwu kbkewvam mhaska...' Perplexity: 27.83\n",
            "  Sample 7: 'bxoq otf\n",
            "cstondhnczd...' Perplexity: 28.26\n",
            "  Sample 8: 'vezyzbjyhctrkhspadlu...' Perplexity: 27.25\n",
            "  Sample 9: 'bzmddwnxvxitblcbmbx ...' Perplexity: 28.30\n",
            "  Sample 10: 'v eguxzyooximashezub...' Perplexity: 27.55\n",
            "\n",
            "Evaluating 3-gram model...\n",
            "  Sample 1: 'rxeol\n",
            "sqiha\n",
            "wejeqoch...' Perplexity: 29.30\n",
            "  Sample 2: 'rssmitwofrljbxofswgv...' Perplexity: 28.90\n",
            "  Sample 3: '#accw #i pgavilibryv...' Perplexity: 29.50\n",
            "  Sample 4: 'oag d e#mvtlehqahubn...' Perplexity: 28.94\n",
            "  Sample 5: 'wu\n",
            "ekme#lrrgxizessgm...' Perplexity: 28.64\n",
            "  Sample 6: 'wzdujhwvruymujvpy\n",
            "hv...' Perplexity: 29.22\n",
            "  Sample 7: 'zj#gxhs  owlznpizoer...' Perplexity: 28.12\n",
            "  Sample 8: 'cp\n",
            "uqorxzaxdqgldd#m#...' Perplexity: 28.36\n",
            "  Sample 9: 'amnqguxtnu\n",
            "##eisqfby...' Perplexity: 29.20\n",
            "  Sample 10: 'hymwlouchvzdqf\n",
            "\n",
            "zbyu...' Perplexity: 28.66\n",
            "\n",
            "Evaluating 4-gram model...\n",
            "  Sample 1: 'lrtpd#s\n",
            "dpx#avjl rej...' Perplexity: 29.02\n",
            "  Sample 2: 'tmlb#gc\n",
            "tt m\n",
            "fmkoa l...' Perplexity: 29.05\n",
            "  Sample 3: 'utwxytxhbrcprtovdrdt...' Perplexity: 29.02\n",
            "  Sample 4: 'hnuxsrk#\n",
            "dqzilsznekk...' Perplexity: 29.02\n",
            "  Sample 5: 'cjf hyarzsyjm#fvjekb...' Perplexity: 29.05\n",
            "  Sample 6: 'f y\n",
            "tocyzk\n",
            "ximyoktnp...' Perplexity: 29.05\n",
            "  Sample 7: 'akyjqbtj#ky\n",
            "kpduxagw...' Perplexity: 29.02\n",
            "  Sample 8: 'uqslpek\n",
            "vfnsvdva\n",
            "ehz...' Perplexity: 29.05\n",
            "  Sample 9: '#fpvenoqgq\n",
            "bmfwccq a...' Perplexity: 29.10\n",
            "  Sample 10: 'wkyrdemkokmdsvutjvgh...' Perplexity: 29.02\n",
            "\n",
            "=== Overall Statistics ===\n",
            "\n",
            "2-gram Model Statistics:\n",
            "Minimum Perplexity: 27.25\n",
            "Maximum Perplexity: 28.63\n",
            "Average Perplexity: 28.07\n",
            "\n",
            "3-gram Model Statistics:\n",
            "Minimum Perplexity: 28.12\n",
            "Maximum Perplexity: 29.50\n",
            "Average Perplexity: 28.88\n",
            "\n",
            "4-gram Model Statistics:\n",
            "Minimum Perplexity: 29.02\n",
            "Maximum Perplexity: 29.10\n",
            "Average Perplexity: 29.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Deliverables**\n",
        "1. A Python Notebook (.ipynb) containing the implementations of the equations above.\n",
        "2. A brief analysis report (100 words) answering: How did changing N (e.g., from Bigram to Trigram) affect the coherence of the generated text and the Perplexity score?"
      ],
      "metadata": {
        "id": "4rwORBV22Hhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As N increased from a bigram (2-gram) to trigram and 4-gram models, the perplexity scores slightly increased rather than decreased. The bigram model achieved the lowest average perplexity (27.99), while trigram (28.72) and 4-gram (28.99) models showed progressively higher values. This suggests that, given the dataset size and smoothing used, higher-order models suffered from data sparsity, leading to less reliable probability estimates. In terms of coherence, bigrams produced more statistically stable but locally limited text, whereas trigrams and 4-grams captured slightly richer context but did not translate into better overall predictability, resulting in higher perplexity."
      ],
      "metadata": {
        "id": "F7fyorwDbxip"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}